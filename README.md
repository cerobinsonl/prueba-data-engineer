# üöÄ **Prueba T√©cnica - Data Engineer Bia**

## üìå **Descripci√≥n**
Este proyecto implementa dos microservicios en **FastAPI** para procesar coordenadas geogr√°ficas desde un archivo CSV, obtener c√≥digos postales mediante la API p√∫blica **postcodes.io**, y almacenar los datos en una base de datos **PostgreSQL**.

---

## üìÅ **Arquitectura**
### üõ†Ô∏è **Componentes Principales**
1. **Microservicio Uploader**:  
   - Recibe un archivo **CSV** con coordenadas (`latitude`, `longitude`) y las almacena en la base de datos.
  
2. **Microservicio Processing**:  
   - Obtiene los c√≥digos postales de cada coordenada usando la API p√∫blica **postcodes.io**.
   - Almacena los datos procesados en la base de datos.

3. **Base de Datos (PostgreSQL)**:  
   - Guarda la informaci√≥n de coordenadas y c√≥digos postales.

### üìä **Diagrama de Arquitectura**
```plaintext
+------------------+       +---------------------+       +----------------+
| Cliente (CSV)    | ----> | Microservicio 1     | ----> | Base de Datos  |
| (Upload CSV)     |       | (Guarda coordenadas)|       | (PostgreSQL)   |
+------------------+       +---------------------+       +----------------+
                                                      |      ‚ñ≤
                                                      |      |
                                                      v      |
+------------------+       +---------------------+       +----------------+
|                 | ----> | Microservicio 2     | ----> | API postcodes.io |
|                 |       | (Consulta API y     |       | (Retorna Postcode)|
|                 |       | actualiza BD)       |       +----------------+
+------------------+       +---------------------+  
```

---

## üõ† **Requisitos**
- **Docker** y **Docker Compose** instalados.
- **PostgreSQL** (se ejecuta dentro del contenedor).
- **Python 3.9** (si deseas correr el c√≥digo localmente).

---

## üöÄ **Instalaci√≥n y Ejecuci√≥n**
### 1Ô∏è‚É£ **Clonar el repositorio**
```bash
git clone https://github.com/tu_usuario/prueba-data-engineer.git
cd prueba-data-engineer
```

### 2Ô∏è‚É£ **Levantar los servicios con Docker**
Ejecuta el siguiente comando para iniciar los microservicios y la base de datos:
```bash
docker-compose up --build
```
Esto iniciar√°:
- **PostgreSQL** en `localhost:5432`
- **Microservicio Uploader** en `http://localhost:8000`
- **Microservicio Processing** en `http://localhost:8001`

---

## üî• **Uso de los Microservicios**
Aqu√≠ tienes ejemplos de c√≥mo probar los endpoints usando **Postman** o `cURL`.

### üì§ **1. Subir un archivo CSV**
- **Endpoint:** `POST http://localhost:8000/upload/`
- **Formato del CSV (`text/csv`):**
```csv
latitude,longitude
51.509865,-0.118092
52.486243,-1.890401
```
- **Ejemplo en `cURL`:**
```bash
curl -X POST "http://localhost:8000/upload/" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@postcodes_geo.csv"
```

- **Ejemplo en Postman**:
  - M√©todo: `POST`
  - URL: `http://localhost:8000/upload/`
  - Body ‚Üí **form-data**:
    - `key`: **file**
    - `value`: (subir archivo `postcodes_geo.csv`)
    - `Content-Type`: `text/csv`

üìå **Respuesta esperada (JSON):**
```json
{
  "rows_processed": 2,
  "message": "Archivo procesado correctamente"
}
```

---

### üì° **2. Procesar coordenadas y obtener c√≥digos postales**
- **Endpoint:** `POST http://localhost:8001/process_batch/`
- **Formato JSON:**
```json
{
  "coordinates": [
    {"latitude": 51.509865, "longitude": -0.118092},
    {"latitude": 52.486243, "longitude": -1.890401}
  ]
}
```
- **Ejemplo en `cURL`:**
```bash
curl -X POST "http://localhost:8001/process_batch/" \
     -H "Content-Type: application/json" \
     -d '{"coordinates": [{"latitude": 51.509865, "longitude": -0.118092},{"latitude": 52.486243, "longitude": -1.890401}]}'
```

üìå **Respuesta esperada (JSON):**
```json
{
  "message": "C√≥digos postales actualizados en la base de datos"
}
```

---

## üõ† **Ejecuci√≥n de Pruebas**
Para ejecutar los tests unitarios en los contenedores:
```bash
docker-compose up --build test_uploader test_processing
```
Esto ejecutar√° `pytest` sobre ambos microservicios y mostrar√° los resultados.

---

## üìö **Tecnolog√≠as Utilizadas**
- **FastAPI** - Framework web para APIs en Python.
- **PostgreSQL** - Base de datos relacional.
- **Docker** - Contenerizaci√≥n de microservicios.
- **pytest** - Framework de testing en Python.

---

## üîÑ **Flujo de Trabajo Implementado**

### üèÅ **1. Inicio del Proyecto**
El desarrollo comenz√≥ con una implementaci√≥n **directa** de dos microservicios en FastAPI:
- **Microservicio Uploader**: Recib√≠a un archivo CSV con coordenadas y lo almacenaba en la base de datos.
- **Microservicio Processing**: Le√≠a las coordenadas desde la base de datos, consultaba la API p√∫blica **postcodes.io** para obtener los c√≥digos postales y actualizaba los registros en la base de datos.

Inicialmente, estos microservicios fueron desarrollados **y probados de forma local** sin contenerizaci√≥n. Esto permit√≠a iterar r√°pidamente sobre la funcionalidad principal antes de pensar en despliegue.

---

### üê≥ **2. Contenerizaci√≥n con Docker**
Una vez verificado que los microservicios funcionaban localmente, se decidi√≥ contenerizarlos usando **Docker** para garantizar la portabilidad y facilitar el despliegue.

Se cre√≥ un `docker-compose.yaml` para levantar los siguientes servicios:
- **PostgreSQL** (como base de datos interna).
- **Microservicio Uploader** (`http://localhost:8000`).
- **Microservicio Processing** (`http://localhost:8001`).

Los **Dockerfiles** correspondientes fueron configurados con las dependencias necesarias para cada microservicio.

‚úÖ **Estado del sistema:**
- Se pod√≠an levantar ambos microservicios con `docker-compose up`.
- Se verific√≥ que la base de datos se iniciaba correctamente y que los microservicios pod√≠an comunicarse con ella.

---

### üì§ **3. Carga del Archivo CSV**
Para probar el **Microservicio Uploader**, se realiz√≥ una primera carga de prueba con un CSV de coordenadas geogr√°ficas:

#### **Ejemplo de archivo `postcodes_geo.csv`**
```csv
latitude,longitude
51.509865,-0.118092
52.486243,-1.890401
```

#### **Ejemplo de solicitud en `cURL`**
```bash
curl -X POST "http://localhost:8000/upload/" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@postcodes_geo.csv"
```

üìå **Respuesta esperada:**
```json
{
  "rows_processed": 2,
  "message": "Archivo procesado correctamente"
}
```

‚úÖ **Estado del sistema:**
- El archivo CSV se guard√≥ correctamente en la base de datos.
- Cada fila qued√≥ registrada con coordenadas, pero sin c√≥digo postal.

---

### üì° **4. Procesamiento de Coordenadas**
Una vez que las coordenadas estaban almacenadas en la base de datos, se implement√≥ el **Microservicio Processing** para obtener los c√≥digos postales correspondientes.

Este servicio:
1. Lee las coordenadas desde la base de datos.
2. Consulta la API p√∫blica `postcodes.io`.
3. Almacena el c√≥digo postal en la base de datos.

#### **Ejemplo de solicitud en `cURL`**
```bash
curl -X POST "http://localhost:8001/process_batch/" \
     -H "Content-Type: application/json" \
     -d '{"coordinates": [{"latitude": 51.509865, "longitude": -0.118092},{"latitude": 52.486243, "longitude": -1.890401}]}'
```

üìå **Respuesta esperada:**
```json
{
  "message": "C√≥digos postales actualizados en la base de datos"
}
```

‚úÖ **Estado del sistema:**
- Se verific√≥ que los c√≥digos postales se obten√≠an correctamente y se actualizaban en la base de datos.

---

### üõ† **5. Implementaci√≥n de Pruebas**
Para validar la funcionalidad de cada microservicio, se implementaron pruebas unitarias usando `pytest`.

Las pruebas cubrieron los siguientes casos:
- ‚úÖ **Microservicio Uploader**:
  - Verificar que se acepta un archivo CSV y se almacenan las coordenadas en la base de datos.
  - Manejo de archivos mal formateados.
  - Validaci√≥n de datos incompletos.
  
- ‚úÖ **Microservicio Processing**:
  - Verificar que se obtienen c√≥digos postales correctamente desde la API.
  - Manejo de respuestas inv√°lidas o errores en la API externa.
  - Verificaci√≥n de la actualizaci√≥n correcta de la base de datos.

Para ejecutar las pruebas en los contenedores:
```bash
docker-compose up --build test_uploader test_processing
```

